{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7286385a-8966-443b-917b-38c8f788a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import math\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from Bio import motifs\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "def extra_upORF(seq_record, upORFs = '', uplength = 20, downlength = 0): #提取启动子序列\n",
    "    if uplength + downlength <= 0:\n",
    "        raise ValueError(\"The length of the upORF cannot be zero or negative.\")\n",
    "        return upORFs\n",
    "    if 'circular' in seq_record.annotations['topology']:\n",
    "        for feature in seq_record.features:\n",
    "            if feature.type == 'CDS':\n",
    "                if feature.location.strand == 1:\n",
    "                    if (feature.location.end - feature.location.start) == len(seq_record.seq) and len(feature.location.parts) >= 2:\n",
    "                        start_index = feature.location.parts[0].start\n",
    "                    else:\n",
    "                        start_index = feature.location.start\n",
    "                    if (start_index - uplength) < 0:\n",
    "                        start_index = start_index + len(seq_record.seq)\n",
    "                        upORF_seq = (seq_record.seq+seq_record.seq)[(start_index - uplength):(start_index + downlength)]\n",
    "                    elif (start_index + downlength) >= len(seq_record.seq):\n",
    "                        upORF_seq = (seq_record.seq+seq_record.seq)[(start_index - uplength):(start_index + downlength)]\n",
    "                    else:\n",
    "                        upORF_seq = seq_record.seq[(start_index - uplength):(start_index + downlength)]\n",
    "                else:\n",
    "                    if (feature.location.end - feature.location.start) == len(seq_record.seq) and len(feature.location.parts) >= 2:\n",
    "                        end_index = feature.location.parts[0].end\n",
    "                    else:\n",
    "                        end_index = feature.location.end\n",
    "                    if (end_index + uplength) >= len(seq_record.seq):\n",
    "                        upORF_seq = (seq_record.seq+seq_record.seq)[(end_index - downlength):(end_index + uplength)].reverse_complement()\n",
    "                    elif (end_index - downlength) < 0:\n",
    "                        end_index = end_index + len(seq_record.seq)\n",
    "                        upORF_seq = (seq_record.seq+seq_record.seq)[(end_index - downlength):(end_index + uplength)].reverse_complement()\n",
    "                    else:\n",
    "                        upORF_seq = seq_record.seq[(end_index - downlength):(end_index + uplength)].reverse_complement()\n",
    "                if len(upORF_seq) < (uplength + downlength):\n",
    "                    continue\n",
    "                elif upORF_seq.strip('ATCG') != '':\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        upORFs += '>' + feature.qualifiers['locus_tag'][0] + '\\n' + str(upORF_seq) + '\\n'\n",
    "                    except:\n",
    "                        upORFs += '>' + feature.qualifiers['protein_id'][0] + '\\n' + str(upORF_seq) + '\\n'\n",
    "        return upORFs\n",
    "    else:\n",
    "        for feature in seq_record.features:\n",
    "            if feature.type == 'CDS':\n",
    "                if feature.location.strand == 1:\n",
    "                    upORF_seq = seq_record.seq[max(0,feature.location.start - uplength):max(0,feature.location.start + downlength)]\n",
    "                else:\n",
    "                    upORF_seq = seq_record.seq[max(0,feature.location.end - downlength):(feature.location.end + uplength)].reverse_complement()\n",
    "                if len(upORF_seq) < (uplength + downlength):\n",
    "                    continue\n",
    "                elif upORF_seq.strip('ATCG') != '':\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        upORFs += '>' + feature.qualifiers['locus_tag'][0] + '\\n' + str(upORF_seq) + '\\n'\n",
    "                    except:\n",
    "                        upORFs += '>' + feature.qualifiers['protein_id'][0] + '\\n' + str(upORF_seq) + '\\n'\n",
    "        return upORFs\n",
    "\n",
    "def notATCG(str):\n",
    "    atcg = ['A', 'T', 'C', 'G']\n",
    "    for i in str:\n",
    "        if i in atcg:\n",
    "            continue\n",
    "        else: \n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def run_motif_finder(assembly, que):\n",
    "    os.chdir(f'/home/zhongshitong/data/up-ORF-motif_local/assembly/{assembly}')\n",
    "    seq_data = SeqIO.parse(f'/data/zhongshitong/Bacteria_reference_genome/ncbi_dataset/data/{assembly}/genomic.gbff', format=\"gb\")\n",
    "    upORF_file = open('upORFseqs.txt', 'w+')\n",
    "    upORFs = ''\n",
    "    CDS_count = 0\n",
    "    for seq_record in seq_data:\n",
    "        upORFs += extra_upORF(seq_record)\n",
    "\n",
    "    upORF_file.write(upORFs)\n",
    "    upORF_file.close()\n",
    "\n",
    "    os.system('nohup meme upORFseqs.txt -dna -w 10 -mod zoops -nmotifs 3 -brief 50000 -nostatus -p 1 -nostatus > /dev/null 2>&1')\n",
    "    que.put(1)\n",
    "\n",
    "def pbar_fun(que, tot):\n",
    "    count = 0\n",
    "    with tqdm(total = tot, desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "        while True:\n",
    "            if not que.empty():\n",
    "                value = que.get(True)\n",
    "                count += 1\n",
    "                pbar.update(1)\n",
    "                if count == tot:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Entrez.email = 'zhongshitong@zju.edu.cn'\n",
    "\n",
    "os.chdir('/home/zhongshitong/data/up-ORF-motif_local')\n",
    "\n",
    "data = pd.read_csv('ncbi_genome-reference-annotation-complete-Ex_Cand_sym-20241211.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c0ed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|████████████████████████████████████████████████| 5.01k/5.01k [4:21:35<00:00, 3.13s/B]\n"
     ]
    }
   ],
   "source": [
    "manager = multiprocessing.Manager()\n",
    "que = manager.Queue()\n",
    "tax = []\n",
    "\n",
    "par = 33\n",
    "tot = len(data['Assembly Accession'])\n",
    "pool = multiprocessing.Pool(par)\n",
    "pool.apply_async(pbar_fun,args=(que, tot))\n",
    "\n",
    "for assembly in data['Assembly Accession']:\n",
    "    try: os.makedirs(f'/home/zhongshitong/data/up-ORF-motif_local/assembly/{assembly}')\n",
    "    except: pass\n",
    "    pool.apply_async(run_motif_finder,(assembly, que))\n",
    "    seq_data = SeqIO.parse(f'/data/zhongshitong/Bacteria_reference_genome/ncbi_dataset/data/{assembly}/genomic.gbff', format=\"gb\")\n",
    "    for seq_record in seq_data:\n",
    "        break\n",
    "    org = seq_record.annotations['organism']\n",
    "    if org.split(' ')[1] in seq_record.annotations['taxonomy'][-1]:\n",
    "        taxo = seq_record.annotations['taxonomy'][:-1].copy()\n",
    "    else:\n",
    "        taxo = seq_record.annotations['taxonomy'].copy()\n",
    "    taxo.insert(0,assembly)\n",
    "    taxo.append(org)\n",
    "    file = open(f'/home/zhongshitong/data/up-ORF-motif_local/assembly/{assembly}/assembly info.txt', 'w+')\n",
    "    file.write(\";\".join(taxo))\n",
    "    file.close()\n",
    "\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed25af7-19bb-4c91-8109-7406f9352415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|██████████████████████████████████████████████████| 5.01k/5.01k [10:45<00:00, 7.76B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motif count: 6787\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total = len(data['Assembly Accession']), desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "    table = pd.DataFrame(columns=[\"Assembly\", \"motif_consensus\", \"motif_degenerate_consensus\", \"motif_instances_number\", \"evalue\", \"Assembly_records_number\"])\n",
    "    non_motif_assembly = []\n",
    "    motifs_data = ''\n",
    "    motifs_fasta = ''\n",
    "    count = 0\n",
    "    ex = []\n",
    "    for i in range(len(data['Assembly Accession'])):\n",
    "        assembly = data['Assembly Accession'][i]\n",
    "        if not pd.isnull(assembly):\n",
    "            pass\n",
    "        else:\n",
    "            assembly = data['GeneBank'][i]\n",
    "        pbar.update(1)\n",
    "        os.chdir(f'/home/zhongshitong/data/up-ORF-motif_local/assembly/{assembly}')\n",
    "        \n",
    "        try:\n",
    "            handle = open(\"meme_out/meme.xml\")\n",
    "            record = motifs.parse(handle, \"meme\")\n",
    "        except:\n",
    "            print(assembly, i)\n",
    "            ex.append(assembly)\n",
    "            continue\n",
    "        match = False\n",
    "        for motif in record:\n",
    "            if motif.evalue < 0.01 and len(motif.alignment.sequences) >= 20 and notATCG(str(motif.degenerate_consensus)):\n",
    "                match = True\n",
    "                temptable = pd.DataFrame([[assembly, str(motif.consensus), str(motif.degenerate_consensus), len(motif.alignment.sequences), motif.evalue, len(record.sequences)]], columns=[\"Assembly\", \"motif_consensus\", \"motif_degenerate_consensus\", \"motif_instances_number\", \"evalue\", \"Assembly_records_number\"])\n",
    "                table = pd.concat([table, temptable])\n",
    "                motif.name = assembly.replace(\".\", \"_\") + '_' + motif.id\n",
    "                motifs_data += format(motif, \"jaspar\").replace(\"None \", \"\")\n",
    "                motifs_fasta = motifs_fasta + '>' + motif.name + '\\n' + str(motif.degenerate_consensus) + '\\n'\n",
    "                count += 1\n",
    "                continue\n",
    "            elif len(motif.alignment.sequences) > 150 and notATCG(str(motif.degenerate_consensus)):\n",
    "                match = True\n",
    "                temptable = pd.DataFrame([[assembly, str(motif.consensus), str(motif.degenerate_consensus), len(motif.alignment.sequences), motif.evalue, len(record.sequences)]], columns=[\"Assembly\", \"motif_consensus\", \"motif_degenerate_consensus\", \"motif_instances_number\", \"evalue\", \"Assembly_records_number\"])\n",
    "                table = pd.concat([table, temptable])\n",
    "                motif.name = assembly.replace(\".\", \"_\") + '_' + motif.id\n",
    "                motifs_data += format(motif, \"jaspar\").replace(\"None \", \"\")\n",
    "                motifs_fasta = motifs_fasta + '>' + motif.name + '\\n' + str(motif.degenerate_consensus) + '\\n'\n",
    "                count += 1\n",
    "                continue\n",
    "            elif motif.evalue > 1 or len(motif.alignment.sequences) < 20:\n",
    "                break\n",
    "        if match:\n",
    "            pass\n",
    "        else:\n",
    "            non_motif_assembly.append(assembly)\n",
    "\n",
    "os.chdir('/home/zhongshitong/data/up-ORF-motif_local')\n",
    "motifs_file = open('motifs_data.txt', 'w+')\n",
    "motifs_file.write(motifs_data)\n",
    "motifs_file.close()\n",
    "motifs_file = open('motifs_data.fasta', 'w+')\n",
    "motifs_file.write(motifs_fasta)\n",
    "motifs_file.close()\n",
    "# 输出motif基本信息\n",
    "table = table.reset_index(drop=True)\n",
    "table.to_csv('up-ORF-motif.csv')\n",
    "#print(non_motif_assembly)\n",
    "print('motif count:', count)\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22146c1c-eb7e-4e79-ad10-c7452e8de5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 载入需要的程序包：grid\n",
      "\n",
      "R[write to console]: \n",
      "\n",
      "Program: 100%|████████████████████████████████████████████████| 6.79k/6.79k [1:59:02<00:00, 1.05s/B]\n",
      "Program: 100%|███████████████████████████████████████████████| 23.0M/23.0M [5:40:06<00:00, 1.13kB/s]\n",
      "Program: 100%|███████████████████████████████████████████████| 23.0M/23.0M [2:04:29<00:00, 3.08kB/s]\n"
     ]
    }
   ],
   "source": [
    "# 画motif系统树\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Queue, Pool\n",
    "\n",
    "\n",
    "def motif_align(i, num, que):\n",
    "    results = []\n",
    "    for j in range(i+1, num+1):\n",
    "        robjects.r(f'd{i}_{j} <- matalign(list(pcms[[{i}]], pcms[[{j}]]),revcomp=FALSE,)')\n",
    "        with (robjects.default_converter + pandas2ri.converter).context():\n",
    "            pd_from_r_df = robjects.conversion.get_conversion().rpy2py(robjects.r(f'd{i}_{j}'))\n",
    "        robjects.r(f'rm(d{i}_{j})')\n",
    "        row = pd_from_r_df['motif1'][0]\n",
    "        col = pd_from_r_df['motif2'][0]\n",
    "        dis = pd_from_r_df['distance'][0]\n",
    "        result = [row, col, dis]\n",
    "        results.append(result.copy())\n",
    "    que.put(results)\n",
    "    \n",
    "def pbar_fun_m(que, que_o, num, par):\n",
    "    count = 0\n",
    "    results = []\n",
    "    with tqdm(total = num, desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "        while True:\n",
    "            if not que.empty():\n",
    "                result = que.get(True)\n",
    "                results = result.copy()\n",
    "                count += 1\n",
    "                que_o.put(results)\n",
    "                pbar.update(1)\n",
    "                if count == num:\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "os.chdir(\"/home/zhongshitong/data/up-ORF-motif_local\")\n",
    "robjects.r('library(\"motifStack\")')\n",
    "robjects.r('library(\"ape\")')\n",
    "robjects.r('setwd(\"/home/zhongshitong/data/up-ORF-motif_local\")')\n",
    "robjects.r('pcms<-importMatrix(\"motifs_data.txt\", format=\"jaspar\", to=\"pcm\")')\n",
    "num = int(str(robjects.r('length(pcms)')).split(' ')[1])\n",
    "robjects.r(f'd <- matalign(list(pcms[[1]], pcms[[2]]),revcomp=FALSE,)')\n",
    "with (robjects.default_converter + pandas2ri.converter).context():\n",
    "    r_df = robjects.conversion.get_conversion().rpy2py(robjects.r('d'))\n",
    "total_data = pd.DataFrame(columns=r_df.columns)\n",
    "robjects.r(f'motifs <- unique(names(pcms[1:{num}]))')\n",
    "robjects.r('da <- matrix(NA, nrow = length(motifs), ncol = length(motifs))')\n",
    "robjects.r('rownames(da) <- colnames(da) <- motifs')\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "que = manager.Queue()\n",
    "que_o = manager.Queue()\n",
    "\n",
    "par = 32+1\n",
    "pool = multiprocessing.Pool(par)\n",
    "pool.apply_async(pbar_fun_m,args=(que, que_o, num, par))\n",
    "\n",
    "for i in range(1, num+1):\n",
    "    pool.apply_async(motif_align,(i, num, que))\n",
    "    \n",
    "pool.close()\n",
    "count = 0\n",
    "with tqdm(total = num*(num-1)/2, desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "    while True:\n",
    "        if not que_o.empty():\n",
    "            results = que_o.get(True)\n",
    "            for result in results:\n",
    "                row = result[0]\n",
    "                col = result[1]\n",
    "                dis = result[2]\n",
    "                robjects.r(f'da[\"{row}\", \"{col}\"] <- {dis}')\n",
    "                robjects.r(f'da[\"{col}\", \"{row}\"] <- {dis}')\n",
    "                count += 1\n",
    "                pbar.update(1)\n",
    "            if count == num*(num-1)/2:\n",
    "                break\n",
    "        else:\n",
    "            continue\n",
    "pool.join()\n",
    "\n",
    "robjects.r('write.csv(da, file = \"motif_align_result.csv\",)')\n",
    "robjects.r('dan <- dist(da)') #借用距离函数，但不直接用距离生成系统树\n",
    "with tqdm(total = num*(num-1)/2, desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "    count = 1\n",
    "    for i in range(num):\n",
    "        for j in range(i+1, num):\n",
    "            robjects.r(f'dan[{count}] <- da[{i+1}, {j+1}]') #更换距离函数得到的数据，改为两个motif之间的比对距离\n",
    "            count += 1\n",
    "            pbar.update(1)\n",
    "robjects.r('hc <- do.call(\"hclust\", list(dan, method=\"single\"))')\n",
    "robjects.r('tr <- as.phylo(hc)')\n",
    "robjects.r('write.tree(tr, file = \"tr_single.txt\",)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098500b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 重读文件重新画树，可跳过\n",
    "robjects.r('da <- read.csv(file = \"motif_align_result.csv\", row.names = 1, header=T)')\n",
    "robjects.r('dan <- dist(da)')\n",
    "with tqdm(total = num*(num-1)/2, desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "    count = 1\n",
    "    for i in range(num):\n",
    "        for j in range(i+1, num):\n",
    "            robjects.r(f'dan[{count}] <- da[{i+1}, {j+1}]')\n",
    "            count += 1\n",
    "            pbar.update(1)\n",
    "robjects.r('hc <- do.call(\"hclust\", list(dan, method=\"single\"))')\n",
    "robjects.r('tr <- as.phylo(hc)')\n",
    "robjects.r('write.tree(tr, file = \"trn_single.txt\",)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50281ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue_AG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|██████████████████████████████████████████████████| 4.91k/4.91k [19:32<00:00, 4.18B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red_TA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|██████████████████████████████████████████████████| 1.15k/1.15k [04:03<00:00, 4.71B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green_TA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|██████████████████████████████████████████████████████| 256/256 [00:21<00:00, 11.9B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|████████████████████████████████████████████████████| 33.0/33.0 [00:04<00:00, 7.22B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|████████████████████████████████████████████████████| 90.0/90.0 [00:09<00:00, 9.06B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|██████████████████████████████████████████████████████| 844/844 [02:49<00:00, 4.97B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|██████████████████████████████████████████████████████| 147/147 [00:25<00:00, 5.74B/s]\n"
     ]
    }
   ],
   "source": [
    "from Bio import Phylo\n",
    "\n",
    "os.chdir(\"/home/zhongshitong/data/up-ORF-motif_local\")\n",
    "tree = Phylo.read(\"tr_single.txt\", \"newick\")\n",
    "motifs_data = tree.get_terminals()\n",
    "\n",
    "def motif_indexing(motif_n, seq_nu = 10):\n",
    "    ass_dir = motif_n.split('_')[0]+'_'+motif_n.split('_')[1]+'.'+motif_n.split('_')[2]\n",
    "\n",
    "    os.chdir(f\"/home/zhongshitong/data/up-ORF-motif_local/assembly/{ass_dir}\")\n",
    "\n",
    "    handle = open(\"meme_out/meme.xml\")\n",
    "    record = motifs.parse(handle, \"meme\")\n",
    "    seq_res = SeqIO.parse(\"upORFseqs.txt\",\"fasta\")\n",
    "    upORF_info = ''\n",
    "    for motif in record:\n",
    "        if motif.id != motif_n.split('_')[-2]+'_'+motif_n.split('_')[-1]:\n",
    "            continue\n",
    "        count = 0\n",
    "        for seq in seq_res:\n",
    "            for i in range(seq_nu):\n",
    "                if motif.instances[i].sequence_name == seq.id:\n",
    "                    upORF_info += '>'+ass_dir+'-'+seq.id+'\\n'+seq.seq+'\\n'\n",
    "                    count += 1\n",
    "            if count == seq_nu:\n",
    "                break\n",
    "    return str(upORF_info)\n",
    "\n",
    "motif_clu = {'blue_AG': ['GCF_000226315_1_motif_1', 'GCF_007859615_1_motif_2'], \n",
    "             'red_TA': ['GCF_018406645_1_motif_2', 'GCF_030408795_1_motif_3'],\n",
    "             'green_TA': ['GCF_018289135_1_motif_1','GCF_006542645_1_motif_1'],}\n",
    "\n",
    "for item in motif_clu:\n",
    "    try: os.makedirs(f'/home/zhongshitong/data/up-ORF-motif_local/filter-results/{item}')\n",
    "    except: pass\n",
    "    upORF_rec = ''\n",
    "    filt_re = tree.common_ancestor(motif_clu[item][0], motif_clu[item][1]).get_terminals()\n",
    "    print(item)\n",
    "    with tqdm(total = len(filt_re), desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "        for f_re in filt_re:\n",
    "            upORF_rec += motif_indexing(str(f_re))\n",
    "            pbar.update(1)\n",
    "\n",
    "    os.chdir(f'/home/zhongshitong/data/up-ORF-motif_local/filter-results/{item}')\n",
    "    upORF_file = open(f\"upORFseqs.txt\", \"w+\")\n",
    "    upORF_file.write(upORF_rec)\n",
    "    upORF_file.close()\n",
    "    os.system('nohup meme upORFseqs.txt -dna -w 10 -mod oops -nmotifs 1 -brief 60000 -nostatus -p 1 -nostatus > /dev/null 2>&1')\n",
    "    \n",
    "TA_motif_clu = {'yellow': ['GCF_008329925_1_motif_2', 'GCF_002222655_1_motif_2'], \n",
    "                 'pink': ['GCF_013003965_1_motif_2', 'GCF_003574315_2_motif_2'],\n",
    "                 'purple': ['GCF_000950575_1_motif_2','GCF_014770185_1_motif_2'],\n",
    "               'orange': ['GCF_035231185_1_motif_3','GCF_030408795_1_motif_3'],}\n",
    "\n",
    "for item in TA_motif_clu:\n",
    "    try: os.makedirs(f'/home/zhongshitong/data/up-ORF-motif_local/filter-results/red_TA_clu/{item}')\n",
    "    except: pass\n",
    "    upORF_rec = ''\n",
    "    filt_re = tree.common_ancestor(TA_motif_clu[item][0], TA_motif_clu[item][1]).get_terminals()\n",
    "    print(item)\n",
    "    with tqdm(total = len(filt_re), desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "        for f_re in filt_re:\n",
    "            upORF_rec += motif_indexing(str(f_re))\n",
    "            pbar.update(1)\n",
    "\n",
    "    os.chdir(f'/home/zhongshitong/data/up-ORF-motif_local/filter-results/red_TA_clu/{item}')\n",
    "    upORF_file = open(f\"upORFseqs.txt\", \"w+\")\n",
    "    upORF_file.write(upORF_rec)\n",
    "    upORF_file.close()\n",
    "    os.system('nohup meme upORFseqs.txt -dna -w 10 -mod oops -nmotifs 1 -brief 60000 -nostatus -p 1 -nostatus > /dev/null 2>&1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06db346d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Program: 100%|██████████████████████████████████████████████████| 5.01k/5.01k [14:51<00:00, 5.62B/s]\n"
     ]
    }
   ],
   "source": [
    "# 物种信息的汇总\n",
    "\n",
    "os.chdir('/home/zhongshitong/data/up-ORF-motif_local')\n",
    "data = pd.read_csv('ncbi_genome-reference-annotation-complete-Ex_Cand_sym-20241211.csv')\n",
    "Ass_data = pd.DataFrame(columns=[\"Assembly accession\", \"Phylum\", \"TA-ORF proportion\"])\n",
    "\n",
    "TA_motifs = tree.common_ancestor(motif_clu['red_TA'][0], motif_clu['red_TA'][1]).get_terminals() + tree.common_ancestor(motif_clu['green_TA'][0], motif_clu['green_TA'][1]).get_terminals()\n",
    "TA_motifs_n = []\n",
    "for item in TA_motifs:\n",
    "    TA_motifs_n.append(str(item))\n",
    "    \n",
    "with tqdm(total = len(data['Assembly Accession']), desc='Program', leave=True, ncols=100, unit='B', unit_scale=True) as pbar:\n",
    "    for assembly in data['Assembly Accession']:\n",
    "        upORFseqs = [seq.id for seq in SeqIO.parse(f\"/home/zhongshitong/data/up-ORF-motif_local/assembly/{assembly}/upORFseqs.txt\",\"fasta\")]\n",
    "        ORFcount = len(upORFseqs)\n",
    "        handle = open(f\"/home/zhongshitong/data/up-ORF-motif_local/assembly/{assembly}/meme_out/meme.xml\")\n",
    "        record = motifs.parse(handle, \"meme\")\n",
    "        TA_ORFcount = 0\n",
    "        for motif in record:\n",
    "            motif_n = assembly.replace(\".\", \"_\") + '_' + motif.id\n",
    "            if motif_n in TA_motifs_n:\n",
    "                TA_ORFcount += len(motif.alignment.sequences)\n",
    "        TAprop = TA_ORFcount/ORFcount\n",
    "        file = open(f'/home/zhongshitong/data/up-ORF-motif_local/assembly/{assembly}/assembly info.txt', 'r')\n",
    "        phy = ''\n",
    "        for line in file:\n",
    "            for word in line.split(';'):\n",
    "                if word[-3:] == 'ota':\n",
    "                    phy = word\n",
    "                    break\n",
    "        file.close()\n",
    "        if phy == '':\n",
    "            handle=Entrez.esearch(db='Assembly',term=assembly) #查找某一物种的基因组，一般返回参考基因组\n",
    "            records=Entrez.read(handle)\n",
    "            pmids=records[\"IdList\"][0]\n",
    "            handle = Entrez.elink(dbfrom=\"genome\", db=\"nucleotide\", LinkName=\"assembly_nuccore_refseq\", id=pmids) #匹配参考基因组的具体核酸id，匹配RefSeq数据\n",
    "            records=Entrez.read(handle)\n",
    "            seq_data = records[0]['LinkSetDb'][0]['Link']\n",
    "            for ids in seq_data:\n",
    "                nuc_id = ids['Id']\n",
    "                handle = Entrez.efetch(db=\"nucleotide\", rettype=\"gbwithparts\", retmode=\"text\", id=nuc_id)\n",
    "                seq_record = SeqIO.read(handle, 'genbank')\n",
    "                for word in seq_record.annotations['taxonomy']:\n",
    "                    if word[-3:] == 'ota':\n",
    "                        phy = word\n",
    "                        break\n",
    "        if phy == '':\n",
    "            phy = 'unknown-' + line.split(';')[2]\n",
    "        Ass_data = pd.concat([Ass_data, pd.DataFrame([{\"Assembly accession\": assembly, \"Phylum\": phy, \"TA-ORF proportion\": TAprop}])], ignore_index=True)\n",
    "        pbar.update(1)\n",
    "        \n",
    "os.chdir('/home/zhongshitong/data/up-ORF-motif_local')\n",
    "Ass_data.to_csv('Ass_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f7d4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:R-env]",
   "language": "python",
   "name": "conda-env-R-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
